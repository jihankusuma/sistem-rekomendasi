# -*- coding: utf-8 -*-
"""SUBMISS_02

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w_4SolQF7aBrRQssUFyY4E7hGYrBphX9

#**System [Recommendation food](https://www.kaggle.com/datasets/schemersays/food-recommendation-system)**
- **Nama:** Jihan Kusumawardhani
- **Email:** jihankusumawwardhani@gmail.com
- **ID Dicoding:** https://www.dicoding.com/users/jihankusumawardhani
- **Modul:** Submission 2 Machine Learning Terapan
-**Dataset:** [Recommendation food](https://www.kaggle.com/datasets/schemersays/food-recommendation-system)

## Import Package dan Libraries
"""

!pip install opendatasets

""">Kode `!pip install opendatasets` digunakan untuk menginstal pustaka Python bernama `opendatasets`. Pustaka ini biasanya digunakan untuk mengunduh *dataset* dari platform seperti Kaggle. Tanda seru `!` di awal perintah menunjukkan bahwa ini adalah perintah *shell* (sistem operasi) yang dijalankan dari dalam lingkungan seperti Jupyter Notebook atau Google Colab."""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Library untuk content-based filtering
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Library untuk collaborative filtering
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import ReduceLROnPlateau

import warnings
warnings.filterwarnings("ignore")

""">* **Import Library Umum:**
    * `pandas as pd`: Mengimpor pustaka Pandas untuk manipulasi dan analisis data (sering digunakan untuk *dataframe*).
    * `numpy as np`: Mengimpor pustaka NumPy untuk komputasi numerik, terutama dengan *array*.
    * `matplotlib.pyplot as plt`: Mengimpor modul `pyplot` dari Matplotlib untuk membuat visualisasi (plot, grafik).
    * `seaborn as sns`: Mengimpor pustaka Seaborn untuk visualisasi data statistik yang lebih menarik.

>* **Library untuk Content-based Filtering:**
    * `TfidfVectorizer`: Digunakan untuk mengubah teks menjadi representasi numerik TF-IDF, penting dalam sistem rekomendasi berbasis konten.
    * `cosine_similarity`: Digunakan untuk menghitung kesamaan kosinus antara dua vektor, sering dipakai untuk menentukan seberapa mirip dua item atau dokumen.


>* **Library untuk Collaborative Filtering:**
    * `tensorflow as tf`: Mengimpor TensorFlow, *framework* *machine learning* yang kuat.
    * `tensorflow import keras`: Mengimpor Keras, API tingkat tinggi untuk membangun dan melatih model *deep learning* yang berjalan di atas TensorFlow.
    * `tensorflow.keras import layers`: Mengimpor modul `layers` dari Keras untuk membangun lapisan-lapisan dalam arsitektur *neural network*.
    * `tensorflow.keras.callbacks import ReduceLROnPlateau`: Mengimpor *callback* yang digunakan untuk mengurangi *learning rate* jika metrik tertentu tidak membaik selama beberapa *epoch* pelatihan.



>* **Manajemen Peringatan:**
    * `import warnings` dan `warnings.filterwarnings("ignore")`: Baris ini digunakan untuk mengabaikan atau menyembunyikan pesan peringatan yang mungkin muncul selama eksekusi kode, agar *output* terlihat lebih bersih.

## Data Loading
"""

import opendatasets as od
od.download('https://www.kaggle.com/datasets/schemersays/food-recommendation-system')

"""> Pada tahapan ini, dataset yang diperlukan untuk proyek, yaitu "food-recommendation-system", diunduh secara programatis dari platform Kaggle. Proses ini diawali dengan mengimpor *library* `opendatasets` yang dikenal dengan alias `od`. Kemudian, fungsi `od.download()` dipanggil dengan menyertakan URL dataset Kaggle sebagai argumen.

> Sistem akan meminta *user* untuk memasukkan kredensial Kaggle, yaitu *username* Kaggle (`jihan kusumawardhani`) dan *Kaggle Key*. Setelah kredensial diverifikasi, proses pengunduhan *file* `food-recommendation-system.zip` akan dimulai, dengan indikator persentase penyelesaian dan kecepatan unduh yang ditampilkan. Tahap ini memastikan ketersediaan data lokal yang diperlukan untuk seluruh proses analisis dan pemodelan selanjutnya.

# **Data Understanding**

### Membaca dataset makanan dan rating
"""

df_makanan = pd.read_csv('/content/food-recommendation-system/1662574418893344.csv')
df_rating = pd.read_csv('/content/food-recommendation-system/ratings.csv')

print(df_makanan.head(3))
print("<=================>")
print(df_makanan.shape)
print("<=================>")
df_makanan.info()

""">Pada bagian ini, proses pemuatan dan inspeksi awal dataset dilakukan sebagai fondasi untuk analisis dan pengembangan sistem rekomendasi makanan. Dua *file* CSV yang menjadi sumber data utama diimport menggunakan library `pandas`.

>1.  **Pemuatan Dataset Makanan:** Dataset pertama, yang berisi informasi detail tentang makanan (`food-recommendation-system/1662574418893344.csv`), dimuat ke dalam DataFrame `df_makanan`. Inspeksi awal (`df_makanan.head()`, `df_makanan.shape`, `df_makanan.info()`) menunjukkan bahwa DataFrame ini memiliki 400 baris dan 5 kolom, dengan kolom-kolom seperti `Food_ID`, `Name`, `C_Type`, `Veg_Non`, dan `Describe` yang semuanya terisi penuh (400 *non-null* entries). Kolom `Food_ID` bertipe integer, sedangkan sisanya bertipe object (string).

>2.  **Pemuatan Dataset Rating:** Dataset kedua, yang kemungkinan besar berisi data rating pengguna (`food-recommendation-system/ratings.csv`), dimuat ke dalam DataFrame `df_rating`. (Catatan: Meskipun kode memuat `df_rating`, detail `df_rating.head()`, `df_rating.shape`, `df_rating.info()` tidak ditampilkan dalam output gambar yang dilampirkan, namun asumsinya data ini juga berhasil dimuat).

>Langkah pemuatan dan inspeksi awal ini esensial untuk memahami struktur, tipe data, dan potensi masalah kualitas data (seperti nilai yang hilang) sebelum melanjutkan ke tahap pembersihan dan rekayasa fitur.

###Cek kategori makanan unik
"""

print(len(df_makanan['C_Type'].unique()))
print(df_makanan['C_Type'].unique())

""">Setelah pemuatan dataset, dilakukan inspeksi terhadap kolom `C_Type` untuk memahami variasi dan keunikan kategori di dalamnya. Kode ini mencetak jumlah nilai unik dan daftar nilai unik itu sendiri.

>Hasil eksekusi menunjukkan bahwa terdapat 16 nilai unik dalam kolom `C_Type`. Daftar nilai unik tersebut meliputi berbagai kategori makanan seperti 'Healthy Food', 'Snack', 'Dessert', 'Japanese', 'Indian', 'French', 'Mexican', 'Italian', 'Chinese', 'Beverage', 'Thai', 'Korean', 'Vietnamese', 'Nepalese', dan 'Spanish'. Namun, terdeteksi adanya duplikasi entri 'Korean', yang mengindikasikan perlunya langkah pembersihan lebih lanjut untuk mengonsolidasikan kategori-kategori yang sama sebelum analisis atau pemodelan.

###Membersihkan nama kategori
"""

df_makanan['C_Type'] = df_makanan['C_Type'].replace([' Korean'], 'Korean')
print(len(df_makanan['C_Type'].unique()))
print(df_makanan['C_Type'].unique())

""">Sebagai langkah penting dalam pra-pemrosesan data untuk memastikan konsistensi dan akurasi, dilakukan konsolidasi pada kolom `C_Type` di DataFrame `df_makanan`. Kode ini secara spesifik menargetkan entri yang memiliki spasi di awal (`' Korean'`) dan menggantinya dengan format tanpa spasi (`'Korean'`).

>Setelah operasi penggantian ini dieksekusi, verifikasi dilakukan dengan menghitung ulang jumlah nilai unik dan mencetak daftar nilai unik yang ada di kolom `C_Type`. Hasil output mengonfirmasi bahwa jumlah kategori unik telah berhasil berkurang menjadi 15, menunjukkan bahwa duplikasi entri 'Korean' telah berhasil diatasi, dan data kini lebih bersih serta siap untuk analisis lebih lanjut.

###Distribusi kategori
"""

df_makanan['C_Type'].value_counts().sort_values().plot(kind='barh', color='maroon')

""">Setelah proses pembersihan data, dilakukan analisis distribusi frekuensi untuk kolom `C_Type` guna memahami proporsi masing-masing jenis kategori makanan dalam dataset. Analisis ini melibatkan perhitungan jumlah kemunculan setiap nilai unik pada kolom `C_Type` menggunakan `df_makanan['C_Type'].value_counts()`, kemudian diurutkan dari yang terendah ke tertinggi menggunakan `.sort_values()`.

>Visualisasi hasil dilakukan menggunakan *bar chart* horizontal (`kind='barh'`) dengan warna *maroon* untuk merepresentasikan frekuensi setiap kategori. Dari plot yang dihasilkan, terlihat jelas bahwa **'Indian' Food merupakan kategori yang paling dominan** dengan jumlah entri tertinggi, diikuti oleh 'Healthy Food' dan 'Dessert'. Sementara itu, kategori seperti 'Vietnamese' dan 'Spanish' memiliki jumlah entri yang relatif sangat sedikit. Visualisasi ini memberikan *insight* awal mengenai komposisi dataset berdasarkan jenis masakan atau tipe makanan, yang krusial untuk memahami representasi data sebelum membangun sistem rekomendasi.
"""

print(df_rating.head(3))
print("<=================>")
print(df_rating.shape)
print("<=================>")
df_rating.info()

""">Setelah dataset makanan, dilakukan inspeksi awal terhadap DataFrame `df_rating` untuk memahami struktur dan karakteristik data rating pengguna. Kode ini mencetak tiga baris pertama DataFrame, informasi mengenai dimensi DataFrame, dan ringkasan informasinya (`.info()`).

>Dari output yang ditampilkan, `df_rating` memiliki 512 entri (baris) dan 3 kolom. Kolom-kolom yang tersedia meliputi `User_ID`, `Food_ID`, dan `Rating`, yang semuanya memiliki 511 *non-null* entries, mengindikasikan adanya satu nilai yang hilang di setiap kolom tersebut. Semua kolom ini terdeteksi bertipe `float64`. Inspeksi ini memberikan gambaran awal tentang data rating yang akan digunakan untuk membangun sistem rekomendasi, termasuk jumlah observasi dan kebutuhan penanganan nilai yang hilang pada tahap pra-pemrosesan selanjutnya.
"""

print('Jumlah User_ID:', len(df_rating['User_ID'].unique()))
print("<=================>")
print('Jumlah Food_ID:', len(df_rating['Food_ID'].unique()))
print("<=================>")
print(df_rating.describe())

""">Pada bagian ini, dilakukan analisis statistik deskriptif untuk memahami karakteristik utama dari kolom-kolom numerik dalam DataFrame `df_rating`. Kode ini secara spesifik mencetak jumlah nilai unik pada kolom `User_ID` dan `Food_ID`, serta menampilkan ringkasan statistik deskriptif dari seluruh kolom numerik dalam DataFrame `df_rating` menggunakan metode `.describe()`.

>Hasil output menunjukkan bahwa terdapat 101 *User_ID* unik dan 310 *Food_ID* unik, yang mengindikasikan bahwa data rating melibatkan 101 pengguna yang memberikan rating pada 310 jenis makanan yang berbeda. Untuk kolom `Rating`, nilai rata-rata (*mean*) rating adalah sekitar 5.43, dengan standar deviasi (*std*) sebesar 2.86. Rentang rating diketahui dari nilai minimum (1.0) hingga nilai maksimum (10.0), serta kuartil pertama (25%) pada 3.0, median (50%) pada 5.0, dan kuartil ketiga (75%) pada 8.0. Informasi ini sangat penting untuk memahami sebaran rating dan aktivitas pengguna serta makanan dalam dataset, yang akan menjadi dasar untuk pengembangan sistem rekomendasi.
"""

sns.displot(df_rating['Rating'], kde=True, bins=10, color='maroon')

""">Visualisasi distribusi data rating merupakan langkah krusial untuk memahami pola umpan balik pengguna terhadap objek yang direkomendasikan. Dari plot distribusi rating yang dihasilkan, dapat diidentifikasi bahwa mayoritas rating pengguna cenderung terkonsentrasi pada nilai-nilai diskrit, khususnya di sekitar angka 3, 5, dan 10. Pola ini mengindikasikan preferensi atau kecenderungan pengguna untuk memberikan rating pada skala tersebut, yang mungkin merefleksikan tingkat kepuasan yang "cukup baik", "baik", dan "sangat baik". Pemahaman terhadap distribusi ini penting untuk tahapan pemodelan selanjutnya, khususnya dalam memilih strategi penanganan *rating* (misal: apakah akan diperlakukan sebagai nilai kontinu atau dikategorikan) dan untuk menginterpretasikan hasil prediksi model rekomendasi.

# **Data Preprocessing**

###Menggabungkan Data
"""

df_gabungan = pd.merge(df_rating, df_makanan[['Food_ID', 'Name', 'C_Type']], on='Food_ID', how='left')
print(df_gabungan.head())
print(df_gabungan.isnull().sum())
df_gabungan = df_gabungan.dropna()

""">Pada tahapan ini, sebuah matriks kosong (`pivot_table`) disiapkan sebagai struktur dasar untuk merepresentasikan umpan balik pengguna dalam format yang akan digunakan untuk pemodelan sistem rekomendasi. Kode tersebut menginisialisasi matriks ini dengan nilai nol di seluruh selnya, yang akan diisi kemudian dengan data rating yang relevan. Matriks ini memiliki dimensi di mana baris merepresentasikan `User_ID` unik dan kolom merepresentasikan `Food_ID` unik, sehingga setiap sel dalam matriks akan menampung rating yang diberikan oleh pengguna tertentu untuk makanan tertentu. Struktur ini fundamental untuk banyak algoritma rekomendasi, terutama yang berbasis *collaborative filtering*, karena memungkinkan representasi *sparse* dari interaksi pengguna-item."""

df_rating = df_rating.dropna()

"""###Urutkan berdasarkan Food_ID"""

df_urut = df_gabungan.sort_values('Food_ID', ascending=True)
print(df_urut.head())
print(len(df_urut['Food_ID'].unique()))
print(df_urut['C_Type'].unique())

""">Pada tahap pra-pemrosesan ini, index dari DataFrame `df_makanan` dikonversi menjadi sebuah list. Langkah ini esensial karena banyak operasi selanjutnya dalam analisis data dan *machine learning* membutuhkan data dalam format list untuk iterasi atau akses indeks yang lebih mudah. Meskipun tidak ada output yang ditampilkan dalam gambar yang dilampirkan, eksekusi sel kode ini akan menghasilkan list yang berisi indeks-indeks dari DataFrame `df_makanan`, yang kemungkinan besar adalah rentang numerik dari 0 hingga jumlah baris dalam DataFrame tersebut. List indeks ini dapat digunakan untuk berbagai keperluan, seperti memetakan kembali hasil analisis ke data asli atau untuk *feature engineering* lebih lanjut.

###Persiapan data makanan tanpa duplikasi
"""

df_prep = df_urut.sort_values('Food_ID').drop_duplicates('Food_ID')
df_prep.loc[df_prep['C_Type'] == 'Healthy Food', 'C_Type'] = 'Healthy_Food'

"""
###Ekstraksi kolom untuk content-based filtering"""

list_id = df_prep['Food_ID'].tolist()
list_nama = df_prep['Name'].tolist()
list_kategori = df_prep['C_Type'].tolist()

print(len(list_id), len(list_nama), len(list_kategori))

""">Pada tahapan pra-pemrosesan data ini, beberapa kolom kunci dari DataFrame `df_makanan`, yaitu `Food_ID`, `Name`, dan `C_Type`, dikonversi menjadi format list. Meskipun output langsung dari proses konversi tidak sepenuhnya terlihat pada gambar yang dilampirkan, tujuan dari langkah ini adalah untuk mempermudah manipulasi data dan integrasi ke dalam model *machine learning* selanjutnya, terutama yang berbasis teks atau untuk operasi yang memerlukan akses indeks yang cepat dan langsung. Konversi ini menghasilkan representasi yang lebih fleksibel untuk fitur-fitur yang akan digunakan dalam pembangunan sistem rekomendasi makanan.

###Membuat dataframe baru
"""

df_makanan_baru = pd.DataFrame({
    'id': list_id,
    'food_name': list_nama,
    'category': list_kategori
})

print(df_makanan_baru.head())
print(df_makanan_baru.sample(5))

"""# **Modeling**

###Content-Based Filtering

#####Membuat TF-IDF vectorizer berdasarkan kategori makanan
"""

tfidf_vect = TfidfVectorizer()
tfidf_vect.fit(df_makanan_baru['category'])
print(tfidf_vect.get_feature_names_out())

tfidf_matrix = tfidf_vect.fit_transform(df_makanan_baru['category'])
print(tfidf_matrix.shape)
print(tfidf_matrix.todense())

"""### Pra-pemrosesan Data: Konversi Vektor TF-IDF ke Matriks Padat

Pada tahapan pra-pemrosesan data ini, representasi fitur teks yang telah diubah menjadi vektor TF-IDF dikonversi menjadi format matriks padat (*dense matrix*) menggunakan fungsi `todense()`. Matriks padat ini, yang kini berisi bobot TF-IDF untuk setiap kata dalam setiap dokumen (ulasan makanan), akan menjadi input langsung untuk model *machine learning* selanjutnya dalam pembangunan sistem rekomendasi.

#####Menampilkan beberapa contoh fitur
"""

df_tfidf = pd.DataFrame(tfidf_matrix.todense(),
                        columns=tfidf_vect.get_feature_names_out(),
                        index=df_makanan_baru['food_name'])
print(df_tfidf.sample(11, axis=1).sample(10, axis=0))

"""#####Matriks cosine similarity

"""

cos_sim = cosine_similarity(tfidf_matrix)
df_cosine = pd.DataFrame(cos_sim, index=df_makanan_baru['food_name'], columns=df_makanan_baru['food_name'])
print('Shape:', df_cosine.shape)
print(df_cosine.sample(5, axis=1).sample(10, axis=0))

def rekomendasi_makanan(nama_makanan, sim_data=df_cosine, items=df_makanan_baru[['food_name', 'category']], top=5):
    # Mengambil indeks kemiripan
    idx_array = sim_data.loc[:, nama_makanan].to_numpy().argpartition(range(-1, -top, -1))
    rekomendasi = sim_data.columns[idx_array[-1:-(top+2):-1]]
    rekomendasi = rekomendasi.drop(nama_makanan, errors='ignore')
    return pd.DataFrame(rekomendasi).merge(items).head(top)

""">Bagian kode program ini didedikasikan untuk mengembangkan sebuah fungsi yang esensial dalam sistem rekomendasi, yaitu `rekomendasi_makanan`, yang menerima input berupa nama makanan dan menghasilkan daftar rekomendasi yang relevan. Fungsi ini dirancang untuk bekerja dengan matriks kemiripan yang telah dihitung sebelumnya, di mana setiap baris dan kolom mewakili item (makanan) dalam dataset.

>Langkah awal dalam fungsi ini melibatkan penggunaan metode `argpartition`. Metode ini secara tidak langsung mempartisi data di sepanjang sumbu yang ditentukan, yang dalam konteks ini digunakan untuk mengambil indeks makanan dengan tingkat kemiripan terbesar dari matriks kemiripan yang ada. Setelah mendapatkan daftar rekomendasi awal, *food_name* (nama makanan yang menjadi input pencarian) akan dibuang dari hasil, sehingga rekomendasi yang ditampilkan tidak menyertakan makanan yang sedang dicari. Pendekatan ini memastikan bahwa pengguna akan menerima rekomendasi makanan yang baru dan beragam, didasarkan pada tingkat kemiripan dengan makanan yang mereka minati.
"""

print(df_makanan_baru[df_makanan_baru['food_name'] == 'banana chips'])
print(rekomendasi_makanan('banana chips'))

"""> Dapat dilihat bahwa fungsi tersebut berhasil mengidentifikasi dan menampilkan 5 nama makanan yang memiliki kategori yang sama dengan makanan yang sebelumnya menjadi input, yaitu kategori 'Snack'. Hasil ini mengonfirmasi bahwa sistem rekomendasi bekerja sesuai tujuan untuk memberikan rekomendasi item (makanan) berdasarkan kemiripan kategorinya, sehingga pengguna mendapatkan variasi makanan yang relevan dalam kategori yang diminati.

###Collaborative Filtering

#####Encoding User_ID dan Food_ID
"""

user_list = df_rating['User_ID'].unique().tolist()
print('User_ID list:', user_list)

user2idx = {user: idx for idx, user in enumerate(user_list)}
idx2user = {idx: user for idx, user in enumerate(user_list)}
print('Mapping User_ID:', user2idx)
print('Mapping indeks ke User_ID:', idx2user)

food_list = df_rating['Food_ID'].unique().tolist()
food2idx = {food: idx for idx, food in enumerate(food_list)}
idx2food = {idx: food for idx, food in enumerate(food_list)}

"""#####Menambahkan kolom encoding pada dataframe rating"""

df_rating['user'] = df_rating['User_ID'].map(user2idx)
df_rating['food'] = df_rating['Food_ID'].map(food2idx)

n_users = len(user2idx)
n_foods = len(idx2food)
print(n_users, n_foods)

df_rating['rating'] = df_rating['Rating'].astype(np.float32)
min_rat = df_rating['rating'].min()
max_rat = df_rating['rating'].max()
print('Jumlah User: {}, Jumlah Food: {}, Rating Min: {}, Rating Max: {}'.format(n_users, n_foods, min_rat, max_rat))

""">Pada tahapan ini, dilakukan pemeriksaan mendalam terhadap karakteristik dasar dari dataset rating (`df_rating`). Kode program secara spesifik menghitung dan menampilkan jumlah nilai unik pada kolom `User_ID` dan `Food_ID`, yang mengindikasikan total pengguna dan total makanan yang terlibat dalam data umpan balik. Selanjutnya, fungsi `.describe()` digunakan untuk mendapatkan ringkasan statistik deskriptif dari semua kolom numerik dalam `df_rating`, termasuk nilai minimum, maksimum, rata-rata (*mean*), dan standar deviasi (*std*) dari kolom `Rating`. Output ini menunjukkan bahwa terdapat 101 pengguna unik dan 310 makanan unik, dengan rentang rating dari 1.0 hingga 10.0. Pemahaman terhadap statistik ini esensial untuk memvalidasi kualitas data, mengidentifikasi potensi *outlier*, dan sebagai dasar untuk strategi pemodelan rekomendasi selanjutnya."""

df_rating = df_rating.sample(frac=1, random_state=42)

"""#####Menyiapkan data untuk training"""

X_data = df_rating[['user', 'food']].values
y_data = df_rating['rating'].apply(lambda x: (x - min_rat) / (max_rat - min_rat)).values

split_index = int(0.8 * df_rating.shape[0])
X_train, X_val = X_data[:split_index], X_data[split_index:]
y_train, y_val = y_data[:split_index], y_data[split_index:]
print(X_data, y_data)

"""Sel kode di atas digunakan untuk membuat variabel `x` dan `y`, diikuti dengan pemisahan data.

#####Membangun model rekomendasi dengan TensorFlow
"""

class RecommenderModel(tf.keras.Model):
    def __init__(self, total_users, total_foods, embed_size, **kwargs):
        super(RecommenderModel, self).__init__(**kwargs)
        self.user_embed = layers.Embedding(total_users, embed_size,
                                           embeddings_initializer='he_normal',
                                           embeddings_regularizer=keras.regularizers.l2(1e-6))
        self.user_bias = layers.Embedding(total_users, 1)
        self.food_embed = layers.Embedding(total_foods, embed_size,
                                           embeddings_initializer='he_normal',
                                           embeddings_regularizer=keras.regularizers.l2(1e-6))
        self.food_bias = layers.Embedding(total_foods, 1)

    def call(self, inputs):
        u_vec = self.user_embed(inputs[:, 0])
        u_bias = self.user_bias(inputs[:, 0])
        f_vec = self.food_embed(inputs[:, 1])
        f_bias = self.food_bias(inputs[:, 1])

        dot = tf.reduce_sum(u_vec * f_vec, axis=1, keepdims=True)
        x_out = dot + u_bias + f_bias
        return tf.nn.sigmoid(x_out)

"""Sel kode di atas digunakan untuk membuat kelas RecommenderModel dengan kelas Model keras."""

model_reco = RecommenderModel(n_users, n_foods, 50)
model_reco.compile(loss=tf.keras.losses.BinaryCrossentropy(),
                   optimizer=keras.optimizers.Adam(learning_rate=0.0001),
                   metrics=[tf.keras.metrics.RootMeanSquaredError()])

""">Pada tahapan ini, model *deep learning* yang telah disusun dikonfigurasi melalui proses kompilasi, yang merupakan langkah esensial sebelum pelatihan model dapat dimulai. Konfigurasi ini melibatkan penetapan tiga komponen utama: fungsi kerugian, *optimizer*, dan metrik evaluasi.

>1.  **Fungsi Kerugian (*Loss Function*):** Model ini menggunakan `Binary Crossentropy` sebagai fungsi kerugian. Pemilihan `Binary Crossentropy` mengindikasikan bahwa model dirancang untuk masalah klasifikasi biner atau situasi di mana *output* yang diprediksi adalah probabilitas untuk dua kelas. Meskipun Anda berfokus pada sistem rekomendasi yang bisa jadi regresi atau multi-kelas, penggunaan *Binary Crossentropy* mungkin relevan jika masalah rekomendasi Anda diformulasikan sebagai klasifikasi implisit (misal: apakah pengguna akan suka/tidak suka).
>2.  ***Optimizer*:** `Adam (Adaptive Moment Estimation)` dipilih sebagai *optimizer*. *Adam* adalah algoritma optimisasi yang populer dan efisien, dikenal karena kemampuannya dalam mengadaptasi *learning rate* untuk setiap parameter model, sehingga mempercepat konvergensi dan meningkatkan stabilitas pelatihan.
>3.  **Metrik Evaluasi:** `Root Mean Squared Error (RMSE)` ditetapkan sebagai metrik evaluasi utama. RMSE adalah metrik yang umum digunakan dalam masalah regresi untuk mengukur seberapa jauh nilai yang diprediksi oleh model menyimpang dari nilai sebenarnya. Nilai RMSE yang lebih rendah menunjukkan akurasi prediksi model yang lebih tinggi.

>Proses kompilasi ini memastikan bahwa model siap untuk dilatih, dengan parameter yang telah ditentukan untuk mengoptimalkan kinerja dan memfasilitasi evaluasi yang akurat.
"""

history = model_reco.fit(X_train, y_train, batch_size=9, epochs=50, validation_data=(X_val, y_val))

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics: RMSE')
plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend(['Train RMSE', 'Validation RMSE'], loc='best')
plt.show()

"""> Visualisasi metrik kinerja model pada *output code cell* di atas memberikan *insight* krusial mengenai proses pembelajaran dan performa model selama pelatihan. Dari plot yang diamati, terlihat adanya **tren penurunan *Root Mean Squared Error* (RMSE) yang konsisten** pada setiap *epoch*, baik untuk data pelatihan (*training data*) maupun data evaluasi (*validation data*). Penurunan ini secara langsung mengindikasikan bahwa model berhasil mempelajari pola dan hubungan dalam data, sehingga akurasi prediksinya terus meningkat seiring dengan proses pelatihan.

> Pada akhir proses pelatihan, visualisasi ini juga menunjukkan bahwa model mencapai **nilai *error* RMSE akhir sebesar 0.2595** pada data pelatihan, dengan *error* pada data validasi sedikit lebih tinggi, yaitu **0.3137**. Perbedaan kecil antara RMSE pelatihan dan validasi ini menunjukkan bahwa model tidak hanya belajar dari data pelatihan tetapi juga mampu menggeneralisasi dengan baik pada data yang belum pernah dilihat sebelumnya. Nilai RMSE yang rendah secara keseluruhan mencerminkan bahwa model dapat memprediksi *rating* atau nilai numerik target dengan tingkat kesalahan yang minimal, yang merupakan indikator kuat dari efektivitas model dalam konteks proyek ini.

#####Mengambil data sample rating
"""

df_sample = pd.read_csv('/content/food-recommendation-system/ratings.csv')
sample_user = df_sample['User_ID'].sample(1).iloc[0]
user_ratings = df_sample[df_sample['User_ID'] == sample_user]

"""Mengambil makanan yang belum pernah dicoba oleh user"""

makanan_belum = df_makanan_baru[~df_makanan_baru['id'].isin(user_ratings['Food_ID'].values)]['id']
makanan_belum = list(set(makanan_belum).intersection(set(food2idx.keys())))
makanan_belum_idx = [[food2idx[x]] for x in makanan_belum]

user_encoded = user2idx[sample_user]
user_food_pairs = np.hstack((np.full((len(makanan_belum_idx), 1), user_encoded), makanan_belum_idx))
prediksi_rating = model_reco.predict(user_food_pairs).flatten()

"""Mengambil 10 rekomendasi teratas"""

top_indices = prediksi_rating.argsort()[-10:][::-1]
rekomendasi_ids = [idx2food[makanan_belum_idx[i][0]] for i in top_indices]

print('Rekomendasi untuk User:', int(sample_user))
print('---' * 10)
print('Makanan yang pernah dinilai tinggi oleh user:')
top_user = user_ratings.sort_values(by='Rating', ascending=False).head(5)['Food_ID'].values
for row in df_makanan_baru[df_makanan_baru['id'].isin(top_user)].itertuples():
    print(row.food_name, ":", row.category)

print('---' * 10)
print('Top 10 rekomendasi makanan:')
for row in df_makanan_baru[df_makanan_baru['id'].isin(rekomendasi_ids)].itertuples():
    print(row.food_name, ":", row.category)

""">Sel kode di atas berfungsi untuk menghasilkan rekomendasi makanan yang dipersonalisasi bagi pengguna dengan `User_ID 41`. Proses ini memanfaatkan model rekomendasi yang telah dibangun, dengan mengidentifikasi pola preferensi pengguna tersebut terhadap berbagai makanan. Dari *output* eksekusi kode, dapat diamati bahwa sistem berhasil menyajikan daftar yang terdiri dari 10 rekomendasi makanan yang relevan untuk `User_ID 41`. Hasil ini menunjukkan kapabilitas model dalam menyediakan saran makanan yang disesuaikan, yang merupakan inti dari fungsionalitas sistem rekomendasi."""